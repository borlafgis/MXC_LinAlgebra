# Vectors

```{python}
import numpy as np
import matplotlib.pyplot as plt
```


## Algebraic and geometric interpretations

Many concepts in linear algebra can be conceptualized using both algebra and
geometry. This is convenient because some concepts are more intuitive from one
of these two points of view.

A vector is an ordered list of numbers like this. Their representation generally
is surrounded by brackets (sometimes angled brackets, or parentheses). Vectors
contain several elements, numbers of any kind: integers or fractions,
real or complex, rational or irrational. 

$$
\begin{bmatrix}
1 \\ 2 \\ 3
\end{bmatrix}
\neq
\begin{bmatrix}
2 \\ 1 \\ 3
\end{bmatrix}
$${#eq-vec-order}

The number of elements in a vector is called the dimensionality of the vector.
In @eq-vec-order, both sides are three dimensional vectors. They are not the
same because the order of these elements is meaningful: the first element on
the left side is $1$, whereas on the right side it is $2$. @eq-vec-size shows
a 2- and 5-dimensional vectors.

$$
\begin{bmatrix}
3 \\ 4
\end{bmatrix}
\quad
\begin{bmatrix}
1 \\ 0 \\ \pi \\ 5i \\ -2
\end{bmatrix}
$${#eq-vec-size}

Vectors can be vertical, case where they are called column vectors, or
horizontal, case where they are called row vectors.

$$
\begin{bmatrix}
1 & 2 & 3 & 5 & 4 \\
\end{bmatrix}
$$

Nomenclature around vectors is a bit confusing because source it uses one of
many conventions. The most common way to refer to vectors is using a lowercase,
bold Latin letter, such as $\mathbf{v}$. Sometimes you'll see a little arrow on top of
the letter $\left( \vec{\mathbf{v}} \right)$, which is used to avoid ambiguity about
whether or not this is referring to a vector. Rarely you may encounter vectors
represented using italicized letters. Here we just use lowercase boldface
letters $\left( \mathbf{v} \right)$.

### Geometric interpretation

In geometric terms a vector represents a straight line with some length and
some direction, which is specified by the numbers contained in the vector.
The starting point of vector is called the tail of the vector, and its end is
called the head, symbolized by an arrowhead. 

Note a vector is defined just by its length and direction respective from the
start: it these could start from any point in space. In other words, vectors
are robust to translation Â¿or rigid body motion?. Thus, even though it may be
tempting to interpret the contents of a 2D vector as a coordinate, this only
holds if the tail of the vector is placed on the origin: the vector and the
coordinates are overlapping. If a vector starts at $(0, 0)$ they are considered
to be in standard position. Such position is convenient for many reasons (it
can be assumed if nothing has stated otherwise).

A vector can be 2-, 3-dimensional, etc. Even though past this point
visualization becomes challenging, the principle remains the same.
It also shows a common theme in linear algebra: the geometric interpretation
is useful up to 3 dimensions, point where is more intuitive to switch back
to algebra.

Note vectors can also contain functions.

$$
\begin{bmatrix}
\sin (x) \\
x \cos(x) \\
x \\
\end{bmatrix}
$${#eq-fun-vector}

@eq-fun-vector is a vector valued function where $x$ is some continuous vector.
However, in this course, I'm only going to be talking about vectors where each
element is a number, not an entire function.

### Python

We will be using Numpy, Matplotlib and their submodules (pyplot) for all the
lessons in this course. A list could be considered a 2D vector, but in most
cases is preferable to use a Numpy array, specially for complex cases.
Transpose swaps, the rows and the columns. This operation can be called as a
function, or as a method of Numpy arrays (`.T`).

When we use the function `plt.plot` we are just specifying the $x$ and the $y$
values to draw a line. The code indicates the line start at the origin
$(0, 0)$, and ends at the $x$, $y$ locations corresponding to the first and
second elements of the vector, respectively. So the $x$ coordinate is at $3$
and the $y$ coordinate is $-2$. The rest of the code sets the aspect of the
figure, adds the cartesian axis lines, the grid and sets the plot extent.

```{python}

# 2-dimensional vector
v2 = [ 3, -2 ]

# 3-dimensional vector
v3 = [ 4, -3, 2 ]

# row to column (or vice-versa):
v3t = np.transpose(v3)


# plot them
plt.plot([0,v2[0]],[0,v2[1]])
plt.axis('equal')
plt.plot([-4, 4],[0, 0],'k--')
plt.plot([0, 0],[-4, 4],'k--')
plt.grid()
plt.axis((-4, 4, -4, 4))
```

3D plotting in Python requires a few actual pieces of code compared to plotting
in 2D. In this case, `ax.plot` is a method of a figure panel (`ax` in
Matplotlib terminology) which has been been set to be projected in 3D.
The first argument are the $x$ coordinates, the second the $y$ coordinates,
ad the third the $z$ coordinates. The rest of the code is just setting the axis,
the extent, etc.

```{python}

# plot the 3D vector
fig = plt.figure(figsize=plt.figaspect(1))
# ax = fig.add_subplot(projection='3d')
ax = plt.axes(projection = '3d')
ax.plot([0, v3[0]],[0, v3[1]],[0, v3[2]],linewidth=3)

# make the plot look nicer
ax.plot([0, 0],[0, 0],[-4, 4],'k--')
ax.plot([0, 0],[-4, 4],[0, 0],'k--')
ax.plot([-4, 4],[0, 0],[0, 0],'k--')
plt.show()
```

### Summary

* Algebraic and the geometric interpretation of a vector
* The difference between a vector and a coordinate and the one case
* The special case where the vector and the coordinate overlap when the vector
*  is being drawn in its standard position.

## Vector addition/subtraction

When doing operations with vectors it is necessary they have the same number of
elements, the same dimensionality.

### Algebraic interpretation

Algebraic addition or subtraction just apply the operation to each
pair of elements.

$$
\begin{bmatrix}
1 \\ 0 \\ 4 \\ 3
\end{bmatrix}
+
\begin{bmatrix}
2 \\ -3 \\ -2 \\ 1
\end{bmatrix}
=
\begin{bmatrix}
3 \\ -3 \\ 2 \\ 4
\end{bmatrix}
$$

### Geometric interpretation

#### Addition

Geometrically, to add two vectors, you put the tail of one vector at the head
of the other (remember, vectors are about length and orientation, not coordinates).
And just draw the line that goes from the tail of the first vector to the head
of the second.

#### Subtraction

Geometrically, vector subtraction has two interpretations.

You can think of subtraction as multiplying the second vector by $-1$, element
by element, and then adding it to the first vector. This flips the direction of
the vector.

The second way to think about vector subtraction is to put both vectors into
the standard position, and then you draw a straight line going from the head of
the negative negative vector ("$-$" sign) to the head of the positive vector.

In both cases the resulting vector could be translated back to the standard position.

In the PDF file there are more exercises so you can get more comfortable with
vector addition and subtraction, both from the algebraic and the geometric
perspectives.

**translated vector V2 so that it starts at the head of Vector V1**

### Python

Vector addition and subtraction requires the use Numpy arrays (lists are
concatenated with the plus sign). They can added or subtracted with just the
`+` or the `-` sign. You can think about the addition of two vectors as going
from the tail of one vector to the head of the other vector when that vector
is translated to be at the end of the first vector.

```{python}

# two vectors in R2
v1 = np.array([ 3, -1 ])
v2 = np.array([ 2,  4 ])

v3 = v1 + v2

# plot them
plt.plot([0, v1[0]],[0, v1[1]],'b',label='v1')
plt.plot([0, v2[0]]+v1[0],[0, v2[1]]+v1[1],'r',label='v2')
plt.plot([0, v3[0]],[0, v3[1]],'k',label='v1+v2')

plt.legend()
plt.axis('square')
plt.axis((-6, 6, -6, 6))
plt.grid()
plt.show()
```

## Vector-scalar multiplication

A scalar is just a single number outside of a vector or a matrix.

*And you'll see in a few minutes why single numbers in linear algebra are called scalars.*

In linear algebra symbology vectors are represented with boldfaced lowercase
Latin letters (e.g., $\mathbf{v}$), matrices with capital boldface letters
(e.g., $\mathbf{M}$), and scalars with lowercase non boldfaced Greek letters
(e.g., $\alpha$). Note this convention is not followed all the time.

$$
\textbf{v}
=
\begin{bmatrix}
-1 \\ 0 \\ 1
\end{bmatrix}
\quad
\textbf{M}
=
\begin{bmatrix}
-1 & 0 & 2 & 8 \\
0 & 1 & 4 & 4 \\
1 & 4 & 9 & 1 \\
\end{bmatrix}
\quad
\alpha = 7
$$

Vector scalar multiplication has both an algebraic and a geometric interpretation.

### Algebraic

Algebraically vector scalar multiplication means to multiply each element by
the scalar.

$$
\lambda \mathbf{v}
=
7
\begin{bmatrix}
-1 \\ 0 \\ 1
\end{bmatrix}
=
\begin{bmatrix}
7 \times -1 \\
7 \times 0 \\
7 \times 1
\end{bmatrix}
=
\begin{bmatrix}
-7 \\ 0 \\ 7
\end{bmatrix}
$$

### Geometric

The geometric interpretation of vector scalar multiplication is to "scale"
the vector according to the scale (no change in direction). If the scalar is
greater than one ($\lambda > 1$), the resulting vector will be longer than the
original, whereas if it is $\lambda \in (0, 1)$, the result will be shorter.
If the scalar is negative ($\lambda < 0$) spins around and points in the other
way (same direction, opposite orientation).

*[The vector line] is actually lying on a one dimensional subspace that goes
infinitely long in [either] direction. And in that sense, which is a more
linear algebra sense, this vector is not actually pointing in a different
direction with regards to the one dimensional subspace, the infinitely long
line that this line or this vector is on. If scaling a vector doesn't change
its angle, that means that all vectors obtaining by scaling one particular
vector are related to each other in a special way: they lie on the same
subspace (see later).*

### Python 

We create a 2D vector `v1` and multiply by `l`, standing for lambda, $\lambda$.
`l = -.3` is negative and its magnitude is smaller than one, which means the
result will be shorter than the original and have the opposite orientation even
though the direction remains the same. with `l = 2.3` the scaled will be longer
and follow the same orientation as the original one.

The original vector is plotted in blue and the scaled version is plotted in red.
The auxiliary variable `axlim` is used to adjust the extent of the plot
according to largest elements in the original and the scaled vectors.

```python
# vector and scalar
v1 = np.array([ 3, -1 ])
l  = 2.3
v1m = v1*l # scalar-modulated

# plot them
plt.plot([0, v1[0]],[0, v1[1]],'b',label='$v_1$')
plt.plot([0, v1m[0]],[0, v1m[1]],'r:',label='$\lambda v_1$')

plt.legend()
plt.axis('square')
axlim = max([max(abs(v1)),max(abs(v1m))])*1.5 # dynamic axis lim
plt.axis((-axlim,axlim,-axlim,axlim))
plt.grid()
plt.show()
```

### Summary

Multiplying a vector by a scalar changes the length but preserves the direction
of that vector (not the orientation). It may seem like trivial operation, but
this idea turns out to be the fundamental insight that leads to eigenvalue
decomposition, one of the most important applications of linear algebra.

# Vector-vector multiplication: the dot product

There are four ways to multiply two vectors:

1. Had Ahmad multiplication, t
2. The dot product, 
3. the cross product
4. the outer product

The dot product is a single number that provides information about the
relationship between two vectors with the same dimensionality. Sometimes it
also is called the scalar product because the result is a single number.
The dot product is the computational cornerstone of many algorithms, such as
convolution, correlation or the Fourier transform.

### Algebraic interpretation (only)

The DOT product is indicated using several different notations.

$$
\alpha
= \mathbf{a} Â· \mathbf{b} = \langle \mathbf{a}, \mathbf{b} \rangle
= \mathbf{a}^{T} \mathbf{b} = \sum^{n}_{i=1} a_i b_i
$$

The dot product is a scalar, so you can refer to its result using a lowercase
greek letters. You also may see a dot between the two vectors or wide angle
brackets. The latter is more commonly used for continuous functions, but
sometimes it is used used for the dot product. $a^{T} b$ notation is the most
common in linear algebra: the first vector transpose $(T)$ times, the second
vector.

$\mathbf{a}^T \mathbf{b}$ indicates the vector dot product assuming
$\mathbf{a}$ and $\mathbf{b}$ are both column vectors. The algebraic
definition of the dot product is just element-wise and sum the results.
Let me unpack this formula by showing you an example. @eq-dot-ew shows the
dot product between two five-dimensional column vectors, $\mathbf{v}$ and
$\mathbf{v}$. The dot product between these two vectors is element-wise
multiplication and then sum.

$$
v=
\begin{bmatrix}
1 \\ 0 \\ 2 \\ 5 \\ -2
\end{bmatrix}
\quad
w=
\begin{bmatrix}
2 \\ 8 \\ -6 \\ 1 \\ 0
\end{bmatrix}
\quad
\mathbf{v}^T \mathbf{w} =
1 \times 2 + 0 \times 8 + 2 \times (-6) + 5 \times 1 + (-2) \times 0 = -5
$${#eq-dot-ew}

### Python

The first step is to create the vectors `v1`and `v2`.

```{python}
v1 = np.array([ 1, 2, 3, 4, 5 ]) # , 6
v2 = np.array([ 0, -4, -3, 6, 5 ])
```

On the barest terms, we could  loop through the elements of the vectors,
multiply the $i^{th}$ element of the vectors, and add to a variable initialized
at $0$.

```{python}
the_sum = 0
for i in range(len(v1)):
    the_sum += v1[i] * v2[i]
print(the_sum)
```

This code can be reduced a bit using Numpy's vectorized operations

```{python}
print(np.sum(np.multiply(v1,v2)), np.sum(v1 * v2))
```

The library also has the specialized function `np.dot` to calculate the dot
product.

```{python}
print(np.dot(v1, v2))
```

It is also possible to calculate the dot product using matrix multiplication
(see next sections).

```{python}
print(np.matmul( v1,v2 ), v1 @ v2)
```

Even though the result is $32$ in all cases, in practice is advisable to use
`np.dot` function for convenience, clarity and speed.

# VIDEO: Dot product properties: associative and distributive


```python
## Distributive property

# create random vectors
n = 10
a = np.random.randn(n)
b = np.random.randn(n)
c = np.random.randn(n)

# the two results
res1 = np.dot( a , (b+c) )
res2 = np.dot(a,b) + np.dot(a,c)

# compare them
print([ res1,res2 ])
```


```python
## Associative property

# create random vectors
n = 5
a = np.random.randn(n)
b = np.random.randn(n)
c = np.random.randn(n)

# the two results
res1 = np.dot( a , np.dot(b,c) )
res2 = np.dot( np.dot(a,b) , c )

# compare them
print(res1)
print(res2)


### special cases where associative property works!
# 1) one vector is the zeros vector
# 2) a==b==c

```


---
# VIDEO: Vector length
---



```python
# a vector
v1 = np.array([ 1, 2, 3, 4, 5, 6 ])

# methods 1-4, just like with the regular dot product, e.g.:
vl1 = np.sqrt( sum( np.multiply(v1,v1)) )

# method 5: take the norm
vl2 = np.linalg.norm(v1)

print(vl1,vl2)
```


---
# VIDEO: The dot product from a geometric perspective
---



```python

# two vectors
v1 = np.array([ 2,  4, -3 ])
v2 = np.array([ 0, -3, -3 ])

# compute the angle (radians) between two vectors
ang = np.arccos( np.dot(v1,v2) / (np.linalg.norm(v1)*np.linalg.norm(v2)) )


# draw them
fig = plt.figure()
# ax = fig.add_subplot(projection='3d')
ax = plt.axes(projection = '3d')
ax.plot([0, v1[0]],[0, v1[1]],[0, v1[2]],'b')
ax.plot([0, v2[0]],[0, v2[1]],[0, v2[2]],'r')

plt.axis((-6, 6, -6, 6))
plt.title('Angle between vectors: %s rad.' %ang)
plt.show()

```


```python
## equivalence of algebraic and geometric dot product formulas

# two vectors
v1 = np.array([ 2,  4, -3 ])
v2 = np.array([ 0, -3, -3 ])


# algebraic
dp_a = np.dot( v1,v2 )

# geometric
dp_g = np.linalg.norm(v1)*np.linalg.norm(v2)*np.cos(ang)

# print dot product to command
print(dp_a)
print(dp_g)

```


---
# VIDEO: Vector Hadamard multiplication
---



```python

# create vectors
w1 = [ 1, 3, 5 ]
w2 = [ 3, 4, 2 ]

w3 = np.multiply(w1,w2)
print(w3)

```


---
# VIDEO: Vector outer product
---



```python

v1 = np.array([  1, 2, 3 ])
v2 = np.array([ -1, 0, 1 ])

# outer product
np.outer(v1,v2)

# terrible programming, but helps conceptually:
op = np.zeros((len(v1),len(v2)))
for i in range(0,len(v1)):
    for j in range(0,len(v2)):
        op[i,j] = v1[i] * v2[j]

print(op)
```


---
# VIDEO: Vector cross product
---



```python
# create vectors
v1  = [ -3,  2, 5 ]
v2  = [  4, -3, 0 ]

# Python's cross-product function
v3a = np.cross( v1,v2 )

# "manual" method
v3b = [ [v1[1]*v2[2] - v1[2]*v2[1]],
        [v1[2]*v2[0] - v1[0]*v2[2]],
        [v1[0]*v2[1] - v1[1]*v2[0]] ]

print(v3a,v3b)


fig = plt.figure()
# ax = fig.add_subplot(projection='3d')
ax = plt.axes(projection = '3d')

# draw plane defined by span of v1 and v2
xx, yy = np.meshgrid(np.linspace(-10,10,10),np.linspace(-10,10,10))
z1 = (-v3a[0]*xx - v3a[1]*yy)/v3a[2]
ax.plot_surface(xx,yy,z1,alpha=.2)

## plot the two vectors
ax.plot([0, v1[0]],[0, v1[1]],[0, v1[2]],'k')
ax.plot([0, v2[0]],[0, v2[1]],[0, v2[2]],'k')
ax.plot([0, v3a[0]],[0, v3a[1]],[0, v3a[2]],'r')


ax.view_init(azim=150,elev=45)
plt.show()
```


---
# VIDEO: Hermitian transpose (a.k.a. conjugate transpose)
---



```python
# create a complex number
z = complex(3,4)

# magnitude
print( np.linalg.norm(z) )

# by transpose?
print( np.transpose(z)*z )

# by Hermitian transpose
print( np.transpose(z.conjugate())*z )


# complex vector
v = np.array( [ 3, 4j, 5+2j, complex(2,-5) ] )
print( v.T )
print( np.transpose(v) )
print( np.transpose(v.conjugate()) )
```

    5.0
    (-7+24j)
    (25+0j)
    [3.+0.j 0.+4.j 5.+2.j 2.-5.j]
    [3.+0.j 0.+4.j 5.+2.j 2.-5.j]
    [3.-0.j 0.-4.j 5.-2.j 2.+5.j]



---
# VIDEO: Unit vector
---



```python

# vector
v1 = np.array([ -3, 6 ])

# mu
mu = 1/np.linalg.norm(v1)

v1n = v1*mu

# plot them
plt.plot([0, v1n[0]],[0, v1n[1]],'r',label='v1-norm',linewidth=5)
plt.plot([0, v1[0]],[0, v1[1]],'b',label='v1')

# axis square
plt.axis('square')
plt.axis(( -6, 6, -6, 6 ))
plt.grid()
plt.legend()
plt.show()
```


---
# VIDEO: Span
---



```python
# set S
S1 = np.array([1, 1, 0])
S2 = np.array([1, 7, 0])

# vectors v and w
v = np.array([1, 2, 0])
w = np.array([3, 2, 1])

# draw vectors
fig = plt.figure()
# ax = fig.add_subplot(projection='3d')
ax = plt.axes(projection = '3d')
ax.plot([0, S1[0]],[0, S1[1]],[.1, S1[2]+.1],'r',linewidth=3)
ax.plot([0, S2[0]],[0, S2[1]],[.1, S2[2]+.1],'r',linewidth=3)

ax.plot([0, v[0]],[0, v[1]],[.1, v[2]+.1],'g',linewidth=3)
ax.plot([0, w[0]],[0, w[1]],[0, w[2]],'b')

# now draw plane
xx, yy = np.meshgrid(range(-15,16), range(-15,16))
cp = np.cross(S1,S2)
z1 = (-cp[0]*xx - cp[1]*yy)*1./cp[2]
ax.plot_surface(xx,yy,z1)

plt.show()
```
